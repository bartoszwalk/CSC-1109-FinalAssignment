{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0631004-d8bc-4326-825d-9d4089a82f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43be6ced-10d6-46e2-ad12-8ca5144579c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import functions\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, NaiveBayes\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "946ac398-e13e-4e1b-9142-03871e2297e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/27 20:30:22 WARN Utils: Your hostname, DESKTOP-FM4F1HL resolves to a loopback address: 127.0.1.1; using 172.31.204.238 instead (on interface eth0)\n",
      "24/11/27 20:30:22 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/27 20:30:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Severity Models\").config(\"spark.executor.memory\", \"8g\").config(\"spark.driver.memory\", \"8g\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "669d0a36-b95b-4619-953d-f5d23b1abdde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "path_to_data = \"results/cleaned_accidents\"\n",
    "df = spark.read.csv(path_to_data, header=False, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42777940-bb6f-4ed2-9fde-9b9fac65f51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.toDF(\"ID\", \"Severity\", \"Year\", \"Month\", \"Hour\",\"City\", \"State\", \"Temperature\", \"Humidity\", \"Pressure\", \"Visibility\", \"Wind_Speed\", \"Precipitation\", \"Weather_Category\", \"Traffic_Signal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b8cc696-2457-4d67-9c3e-da14ca089582",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30084901-09f6-4439-b400-1232fd2a7e21",
   "metadata": {},
   "source": [
    "### Logistic Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97d2d655-a4f9-4340-922d-f877b1348144",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_cols = [\"City\", \"State\", \"Weather_Category\"]\n",
    "stages = []\n",
    "\n",
    "for column in string_cols:\n",
    "    indexer = StringIndexer(inputCol=column, outputCol=f\"{column}Index\", handleInvalid=\"skip\")\n",
    "    stages += [indexer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08a19503-e251-4213-90bf-8a6604ab13d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = [\"Month\", \"Hour\", \"Temperature\", \"Humidity\", \"Pressure\", \"Visibility\", \"Wind_Speed\", \"Precipitation\", \"Traffic_Signal\"]\n",
    "feature_cols = [f\"{col}Index\" for col in string_cols] + numerical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a916720a-d892-4bce-91a2-6300f9807159",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_stages = stages.copy()\n",
    "assembler = VectorAssembler(inputCols=numerical_cols, outputCol=\"features\")\n",
    "stages.append(assembler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9258ffd0-de09-4e1f-911a-ae5ba0c92e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(featuresCol='features', labelCol='Severity', family=\"multinomial\")\n",
    "stages.append(log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a4ae138-f779-48b7-8fa9-769dd2f46662",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c36dccc0-eb00-4992-9ab8-d79fb086e669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/27 20:30:50 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_data, test_data = df.randomSplit([0.8, 0.2])\n",
    "test_data_dt = test_data.select(\"*\")\n",
    "test_data_nb = test_data.select(\"*\")\n",
    "test_data_rf = test_data.select(\"*\")\n",
    "lr_model = pipeline.fit(train_data)\n",
    "predictions = lr_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dfbebb2-e358-4ac5-8c90-3a0e2d183070",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 114:======================================>                (12 + 5) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_Accuracy: 0.8411467780755443\n",
      "lr_Precision: 0.7477137470393347\n",
      "lr_Recall: 0.8411467780755443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lr_accuracy_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Severity\", predictionCol=\"prediction\", metricName=\"accuracy\"\n",
    ")\n",
    "lr_accuracy = lr_accuracy_evaluator.evaluate(predictions)\n",
    "\n",
    "lr_precision_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Severity\", predictionCol=\"prediction\", metricName=\"weightedPrecision\"\n",
    ")\n",
    "lr_precision = lr_precision_evaluator.evaluate(predictions)\n",
    "\n",
    "lr_recall_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Severity\", predictionCol=\"prediction\", metricName=\"weightedRecall\"\n",
    ")\n",
    "lr_recall = lr_recall_evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"lr_Accuracy: {lr_accuracy}\\nlr_Precision: {lr_precision}\\nlr_Recall: {lr_recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe63a3b-756f-4aa9-bf1c-7cfe8e6eb3a7",
   "metadata": {},
   "source": [
    "### Decision Tree Model with 5 Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b21657f3-230e-459b-9d5a-cbf9e13ebc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_stages = base_stages.copy()\n",
    "feature_columns_dt = [f for f in feature_cols if f not in [\"CityIndex\"]]\n",
    "assembler = VectorAssembler(inputCols=feature_columns_dt, outputCol=\"features\")\n",
    "dec_tree = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"Severity\", predictionCol=\"dt_prediction\", maxDepth=5, maxBins=100)\n",
    "decision_tree_stages.append(assembler)\n",
    "decision_tree_stages.append(dec_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f37894f-4611-4e41-83ca-321a75f808fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tree_pipeline = Pipeline(stages=decision_tree_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff67de14-5012-45cd-93bb-897092ae11a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dec_tree_model = dec_tree_pipeline.fit(train_data)\n",
    "dec_tree_predictions = dec_tree_model.transform(test_data_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8976c94e-f80b-45a5-9e72-48ed0893edb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 146:==========================>                             (8 + 9) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt_tree_Accuracy: 0.8412394237633264, dt_tree_Precision: 0.7708548205361282, dt_tree_Recall: 0.8412394237633263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dt_tree_accuracy_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Severity\", predictionCol=\"dt_prediction\", metricName=\"accuracy\"\n",
    ")\n",
    "dt_tree_accuracy = dt_tree_accuracy_evaluator.evaluate(dec_tree_predictions)\n",
    "\n",
    "dt_tree_precision_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Severity\", predictionCol=\"dt_prediction\", metricName=\"weightedPrecision\"\n",
    ")\n",
    "dt_tree_precision = dt_tree_precision_evaluator.evaluate(dec_tree_predictions)\n",
    "\n",
    "dt_tree_recall_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Severity\", predictionCol=\"dt_prediction\", metricName=\"weightedRecall\"\n",
    ")\n",
    "dt_tree_recall = dt_tree_recall_evaluator.evaluate(dec_tree_predictions)\n",
    "\n",
    "print(f\"dt_tree_Accuracy: {dt_tree_accuracy}, \\ndt_tree_Precision: {dt_tree_precision}, \\ndt_tree_Recall: {dt_tree_recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d89877-ca57-4b0a-991f-0f2b263357a7",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78ceb6b6-e112-4f36-aa4f-e467ae8ceffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_stages = base_stages.copy()\n",
    "feature_columns_rf = [f for f in feature_cols if f not in [\"CityIndex\"]]\n",
    "assembler = VectorAssembler(inputCols=feature_columns_rf, outputCol=\"features\")\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", predictionCol=\"rf_prediction\", labelCol=\"Severity\", numTrees=20, maxDepth=8, maxBins=100)\n",
    "random_forest_stages.append(assembler)\n",
    "random_forest_stages.append(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fe97dab-d797-45f1-a9c0-e28a6620579e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/27 20:32:43 WARN DAGScheduler: Broadcasting large task binary with size 1125.5 KiB\n",
      "24/11/27 20:32:46 WARN DAGScheduler: Broadcasting large task binary with size 1681.7 KiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rf_pipeline = Pipeline(stages=random_forest_stages)\n",
    "rf_model = rf_pipeline.fit(train_data)\n",
    "rf_predictions = rf_model.transform(test_data_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "896c74a2-d90f-44f5-a933-286c516fe4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/27 20:32:50 WARN DAGScheduler: Broadcasting large task binary with size 1035.2 KiB\n",
      "24/11/27 20:32:56 WARN DAGScheduler: Broadcasting large task binary with size 1035.2 KiB\n",
      "24/11/27 20:33:01 WARN DAGScheduler: Broadcasting large task binary with size 1035.2 KiB\n",
      "[Stage 184:================================================>      (15 + 2) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_Accuracy: 0.8412755068206731\n",
      "rf_Precision: 0.7902760657220946\n",
      "rf_Recall: 0.841275506820673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rf_accuracy_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Severity\", predictionCol=\"rf_prediction\", metricName=\"accuracy\"\n",
    ")\n",
    "rf_accuracy = rf_accuracy_evaluator.evaluate(rf_predictions)\n",
    "\n",
    "rf_precision_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Severity\", predictionCol=\"rf_prediction\", metricName=\"weightedPrecision\"\n",
    ")\n",
    "rf_precision = rf_precision_evaluator.evaluate(rf_predictions)\n",
    "\n",
    "rf_recall_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Severity\", predictionCol=\"rf_prediction\", metricName=\"weightedRecall\"\n",
    ")\n",
    "rf_recall = rf_recall_evaluator.evaluate(rf_predictions)\n",
    "\n",
    "print(f\"rf_Accuracy: {rf_accuracy}\\nrf_Precision: {rf_precision}\\nrf_Recall: {rf_recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1c475c9-7ae0-4695-8e22-994f88914875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature StateIndex has importance: 0.6037848106498739\n",
      "Feature Weather_CategoryIndex has importance: 0.06833850694167891\n",
      "Feature Month has importance: 0.12970612363723588\n",
      "Feature Hour has importance: 0.02085366264488215\n",
      "Feature Temperature has importance: 0.008489094352004855\n",
      "Feature Humidity has importance: 0.004754051844682844\n",
      "Feature Pressure has importance: 0.03475353256868155\n",
      "Feature Visibility has importance: 0.0059660196050164245\n",
      "Feature Wind_Speed has importance: 0.005004625531001442\n",
      "Feature Precipitation has importance: 0.04154513892238491\n",
      "Feature Traffic_Signal has importance: 0.07680443330255714\n"
     ]
    }
   ],
   "source": [
    "feature_importances_rf = rf_model.stages[-1].featureImportances\n",
    "for index, feature in enumerate(feature_importances_rf):\n",
    "    print(f\"Feature {feature_columns_rf[index]} has importance: {feature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2da670b-e783-4dd3-b3af-94be227f3c55",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0643309e-7ce3-4b0c-bfeb-8cd0afe4b332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6eb495d4-7b36-4ecb-bfec-d30628434517",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_nb = train_data.select(\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37da5723-576b-44e3-9547-7ce6a712ddd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "min_temp = train_data_nb.agg(functions.min(\"Temperature\")).collect()[0][0]\n",
    "min_temp = float(min_temp)\n",
    "train_data_nb = train_data_nb.withColumn(\"Temperature\", col(\"Temperature\") + abs(min_temp))\n",
    "test_data_nb = test_data_nb.withColumn(\"Temperature\", col(\"Temperature\") + abs(min_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae5b8d46-1a09-46d3-83ba-c5b62fefb75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_stages = base_stages.copy()\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "nb = NaiveBayes(featuresCol=\"features\", labelCol=\"Severity\", modelType=\"multinomial\", predictionCol=\"nb_prediction\")\n",
    "naive_bayes_stages.append(assembler)\n",
    "naive_bayes_stages.append(nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37af1920-e8c3-4016-8abc-34c4ea8b7738",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "nb_pipeline = Pipeline(stages=naive_bayes_stages)\n",
    "nb_model = nb_pipeline.fit(train_data_nb)\n",
    "nb_predictions = nb_model.transform(test_data_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb6d031a-317f-4ea5-bff0-1b7f7261e9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 214:==========================>                             (8 + 9) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_Accuracy: 0.060084141788861456\n",
      "nb_Precision: 0.6899526430602134\n",
      "nb_Recall: 0.060084141788861456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "nb_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Severity\", predictionCol=\"nb_prediction\", metricName=\"accuracy\"\n",
    ")\n",
    "nb_accuracy = nb_evaluator.evaluate(nb_predictions)\n",
    "\n",
    "nb_precision_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Severity\", predictionCol=\"nb_prediction\", metricName=\"weightedPrecision\"\n",
    ")\n",
    "nb_precision = nb_precision_evaluator.evaluate(nb_predictions)\n",
    "\n",
    "nb_recall_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Severity\", predictionCol=\"nb_prediction\", metricName=\"weightedRecall\"\n",
    ")\n",
    "nb_recall = nb_recall_evaluator.evaluate(nb_predictions)\n",
    "\n",
    "print(f\"nb_Accuracy: {nb_accuracy}\\nnb_Precision: {nb_precision}\\nnb_Recall: {nb_recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796a0dd4-18ff-4ebc-abd5-654c54037051",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
